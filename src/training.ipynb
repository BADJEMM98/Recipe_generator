{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'experimental_functions_run_eagerly' from 'tensorflow.python.eager.def_function' (c:\\Users\\badje\\OneDrive\\Bureau\\Cours_M2\\NLP\\projet\\Recipe_generator\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [2], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m GPT2Tokenizer, TFGPT2Model, GPT2Config\n",
      "File \u001b[1;32mc:\\Users\\badje\\OneDrive\\Bureau\\Cours_M2\\NLP\\projet\\Recipe_generator\\venv\\lib\\site-packages\\tensorflow\\__init__.py:51\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mimport\u001b[39;00m autograph\n\u001b[0;32m     50\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mimport\u001b[39;00m bitwise\n\u001b[1;32m---> 51\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mimport\u001b[39;00m compat\n\u001b[0;32m     52\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mimport\u001b[39;00m config\n\u001b[0;32m     53\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mimport\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\badje\\OneDrive\\Bureau\\Cours_M2\\NLP\\projet\\Recipe_generator\\venv\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\__init__.py:37\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39m\"\"\"Compatibility functions.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[39mThe `tf.compat` module contains two sets of compatibility functions.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m v1\n\u001b[0;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m v2\n\u001b[0;32m     39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m \u001b[39mimport\u001b[39;00m forward_compatibility_horizon\n",
      "File \u001b[1;32mc:\\Users\\badje\\OneDrive\\Bureau\\Cours_M2\\NLP\\projet\\Recipe_generator\\venv\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\__init__.py:30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m autograph\n\u001b[0;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m bitwise\n\u001b[1;32m---> 30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m compat\n\u001b[0;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m config\n\u001b[0;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\badje\\OneDrive\\Bureau\\Cours_M2\\NLP\\projet\\Recipe_generator\\venv\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\compat\\__init__.py:37\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39m\"\"\"Compatibility functions.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[39mThe `tf.compat` module contains two sets of compatibility functions.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m v1\n\u001b[0;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m v2\n\u001b[0;32m     39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m \u001b[39mimport\u001b[39;00m forward_compatibility_horizon\n",
      "File \u001b[1;32mc:\\Users\\badje\\OneDrive\\Bureau\\Cours_M2\\NLP\\projet\\Recipe_generator\\venv\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\compat\\v1\\__init__.py:31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv1\u001b[39;00m \u001b[39mimport\u001b[39;00m autograph\n\u001b[0;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv1\u001b[39;00m \u001b[39mimport\u001b[39;00m bitwise\n\u001b[1;32m---> 31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv1\u001b[39;00m \u001b[39mimport\u001b[39;00m config\n\u001b[0;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv1\u001b[39;00m \u001b[39mimport\u001b[39;00m data\n\u001b[0;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv1\u001b[39;00m \u001b[39mimport\u001b[39;00m debugging\n",
      "File \u001b[1;32mc:\\Users\\badje\\OneDrive\\Bureau\\Cours_M2\\NLP\\projet\\Recipe_generator\\venv\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\config\\__init__.py:14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcontext\u001b[39;00m \u001b[39mimport\u001b[39;00m LogicalDeviceConfiguration\n\u001b[0;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcontext\u001b[39;00m \u001b[39mimport\u001b[39;00m PhysicalDevice\n\u001b[1;32m---> 14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdef_function\u001b[39;00m \u001b[39mimport\u001b[39;00m experimental_functions_run_eagerly\n\u001b[0;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdef_function\u001b[39;00m \u001b[39mimport\u001b[39;00m experimental_run_functions_eagerly\n\u001b[0;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdef_function\u001b[39;00m \u001b[39mimport\u001b[39;00m functions_run_eagerly\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'experimental_functions_run_eagerly' from 'tensorflow.python.eager.def_function' (c:\\Users\\badje\\OneDrive\\Bureau\\Cours_M2\\NLP\\projet\\Recipe_generator\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import GPT2Tokenizer, TFGPT2Model, GPT2Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', lang='fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.path.dirname(os.path.realpath(\"__file__\"))\n",
    "repo_dir = os.path.dirname(current_dir)\n",
    "DATA_FILE = os.path.join(repo_dir,\"data\",\"cleaned_data.csv\")\n",
    "data = pd.read_csv(DATA_FILE, encoding=\"utf-8\",sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Type'] = df[\"Type\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nom</th>\n",
       "      <th>Ingredients</th>\n",
       "      <th>Ustensiles</th>\n",
       "      <th>Etapes</th>\n",
       "      <th>recettes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soupe veloute potimarron pomme terre</td>\n",
       "      <td>2 pomme terre 2 oignon hache   3 gousse ail ha...</td>\n",
       "      <td>louche mixeur plonger blender chauffer couteau...</td>\n",
       "      <td>etape 1 enlever ecorce pepin potimarron obliga...</td>\n",
       "      <td>soupe veloute potimarron pomme terre  2 pomme ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>soupe oignon</td>\n",
       "      <td>4 oignon   50 gramme beurre   1 c.a. huile   1...</td>\n",
       "      <td>louche mixeur plonger blender chauffer saladie...</td>\n",
       "      <td>etape 1 pelez emincer oignon etape 2 faire rev...</td>\n",
       "      <td>soupe oignon  4 oignon   50 gramme beurre   1 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>veloute potiron</td>\n",
       "      <td>1 oignon   1 quartier potiron 1 brique creme f...</td>\n",
       "      <td>louche mixeur plonger couteau cocotte fonte po...</td>\n",
       "      <td>etape 1 couper chair potiron gros de etape 2 c...</td>\n",
       "      <td>veloute potiron  1 oignon   1 quartier potiron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>veloute butternut cannelle</td>\n",
       "      <td>1 oignon   1 c.a. creme frais   1 pincee canne...</td>\n",
       "      <td>louche mixeur plonger couteau cuillere bois po...</td>\n",
       "      <td>etape 1 couper butternut gros cube etape 2 cou...</td>\n",
       "      <td>veloute butternut cannelle  1 oignon   1 c.a. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tarte poireau lardon</td>\n",
       "      <td>250 gramme farine   140 gramme beurre   2 c....</td>\n",
       "      <td>moule tarte four couteau pinceau rape poele sa...</td>\n",
       "      <td>etape 1 prechauffer four 210 degre c thermosta...</td>\n",
       "      <td>tarte poireau lardon    250 gramme farine   14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47335</th>\n",
       "      <td>liqueur genepi</td>\n",
       "      <td>40 morceau sucre   40 brin genepi   1 l alco...</td>\n",
       "      <td>entonnoir balance cuisine</td>\n",
       "      <td>etape 1 transvaser litre alcool gros bouteille...</td>\n",
       "      <td>liqueur genepi    40 morceau sucre   40 brin g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47336</th>\n",
       "      <td>caipirinha</td>\n",
       "      <td>1 dose jus citron vert frais 15 millilitre j...</td>\n",
       "      <td>cuillere bois shaker</td>\n",
       "      <td>etape 1 shaker melanger ingredient glace pilee...</td>\n",
       "      <td>caipirinha    1 dose jus citron vert frais 15 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47337</th>\n",
       "      <td>kombucha maison citron gingembre</td>\n",
       "      <td>1 morceau gingembre raper   100 gramme sucre...</td>\n",
       "      <td>casserole balance cuisine</td>\n",
       "      <td>etape 1 commencer realiser sirop chauffer eau ...</td>\n",
       "      <td>kombucha maison citron gingembre    1 morceau ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47338</th>\n",
       "      <td>gin tonic</td>\n",
       "      <td>4 cl gin   2 rondelle citron   8 cl tonic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>etape 1 verser glaçon verre etape 2 ajouter gi...</td>\n",
       "      <td>gin tonic    4 cl gin   2 rondelle citron   8 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47339</th>\n",
       "      <td>americano cocktail</td>\n",
       "      <td>4 cl vermouth italien 1 citron zeste 1 orang...</td>\n",
       "      <td>presse ail saladier</td>\n",
       "      <td>etape 1 preparer grand tumbler grand verre met...</td>\n",
       "      <td>americano cocktail    4 cl vermouth italien 1 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47340 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Nom  \\\n",
       "0      soupe veloute potimarron pomme terre   \n",
       "1                              soupe oignon   \n",
       "2                           veloute potiron   \n",
       "3                veloute butternut cannelle   \n",
       "4                      tarte poireau lardon   \n",
       "...                                     ...   \n",
       "47335                        liqueur genepi   \n",
       "47336                            caipirinha   \n",
       "47337      kombucha maison citron gingembre   \n",
       "47338                             gin tonic   \n",
       "47339                    americano cocktail   \n",
       "\n",
       "                                             Ingredients  \\\n",
       "0      2 pomme terre 2 oignon hache   3 gousse ail ha...   \n",
       "1      4 oignon   50 gramme beurre   1 c.a. huile   1...   \n",
       "2      1 oignon   1 quartier potiron 1 brique creme f...   \n",
       "3      1 oignon   1 c.a. creme frais   1 pincee canne...   \n",
       "4        250 gramme farine   140 gramme beurre   2 c....   \n",
       "...                                                  ...   \n",
       "47335    40 morceau sucre   40 brin genepi   1 l alco...   \n",
       "47336    1 dose jus citron vert frais 15 millilitre j...   \n",
       "47337    1 morceau gingembre raper   100 gramme sucre...   \n",
       "47338          4 cl gin   2 rondelle citron   8 cl tonic   \n",
       "47339    4 cl vermouth italien 1 citron zeste 1 orang...   \n",
       "\n",
       "                                              Ustensiles  \\\n",
       "0      louche mixeur plonger blender chauffer couteau...   \n",
       "1      louche mixeur plonger blender chauffer saladie...   \n",
       "2      louche mixeur plonger couteau cocotte fonte po...   \n",
       "3      louche mixeur plonger couteau cuillere bois po...   \n",
       "4      moule tarte four couteau pinceau rape poele sa...   \n",
       "...                                                  ...   \n",
       "47335                          entonnoir balance cuisine   \n",
       "47336                               cuillere bois shaker   \n",
       "47337                          casserole balance cuisine   \n",
       "47338                                                NaN   \n",
       "47339                                presse ail saladier   \n",
       "\n",
       "                                                  Etapes  \\\n",
       "0      etape 1 enlever ecorce pepin potimarron obliga...   \n",
       "1      etape 1 pelez emincer oignon etape 2 faire rev...   \n",
       "2      etape 1 couper chair potiron gros de etape 2 c...   \n",
       "3      etape 1 couper butternut gros cube etape 2 cou...   \n",
       "4      etape 1 prechauffer four 210 degre c thermosta...   \n",
       "...                                                  ...   \n",
       "47335  etape 1 transvaser litre alcool gros bouteille...   \n",
       "47336  etape 1 shaker melanger ingredient glace pilee...   \n",
       "47337  etape 1 commencer realiser sirop chauffer eau ...   \n",
       "47338  etape 1 verser glaçon verre etape 2 ajouter gi...   \n",
       "47339  etape 1 preparer grand tumbler grand verre met...   \n",
       "\n",
       "                                                recettes  \n",
       "0      soupe veloute potimarron pomme terre  2 pomme ...  \n",
       "1      soupe oignon  4 oignon   50 gramme beurre   1 ...  \n",
       "2      veloute potiron  1 oignon   1 quartier potiron...  \n",
       "3      veloute butternut cannelle  1 oignon   1 c.a. ...  \n",
       "4      tarte poireau lardon    250 gramme farine   14...  \n",
       "...                                                  ...  \n",
       "47335  liqueur genepi    40 morceau sucre   40 brin g...  \n",
       "47336  caipirinha    1 dose jus citron vert frais 15 ...  \n",
       "47337  kombucha maison citron gingembre    1 morceau ...  \n",
       "47338  gin tonic    4 cl gin   2 rondelle citron   8 ...  \n",
       "47339  americano cocktail    4 cl vermouth italien 1 ...  \n",
       "\n",
       "[47340 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tokens'] = data['recettes'].apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\badje\\AppData\\Local\\Temp\\ipykernel_25620\\1383507977.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X = np.array(data['tokens'].to_list())\n"
     ]
    }
   ],
   "source": [
    "X = np.array(data['tokens'].to_list())\n",
    "y = np.array(data['Type'].to_list())\n",
    "\n",
    "oov_tokens = ['s','Entrée']\n",
    "tokenizer.add_tokens(oov_tokens)\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "max_length = 512\n",
    "sequences = tokenizer.batch_encode_plus(data['recettes'].to_list(), padding=True, truncation=True, return_tensors='tf')\n",
    "\n",
    "# num_classes = len(np.unique(y))\n",
    "# y = tf.keras.utils.to_categorical(y, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([47340, 1024])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(sequences['input_ids'].numpy(), sequences['attention_mask'].numpy(), test_size=0.2, random_state=42)\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X = sequences['input_ids'].numpy()\n",
    "y = sequences['attention_mask'].numpy()\n",
    "input_dim = X.shape[1]\n",
    "\n",
    "# Reshape the input data to a 3D tensor\n",
    "batch_size = X.shape[0]\n",
    "sequence_length = 1  # Set the sequence length to 1\n",
    "X = np.reshape(X, (batch_size, sequence_length, input_dim))\n",
    "\n",
    "output_dim = y.shape[1]\n",
    "\n",
    "# Reshape the target data to a 2D tensor\n",
    "Y = np.reshape(y, (batch_size, output_dim))\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[   83, 10602,   502, ..., 50257, 50257, 50257]],\n",
       "\n",
       "       [[37424,    68,  1093, ..., 50257, 50257, 50257]],\n",
       "\n",
       "       [[   70,   559, 19503, ..., 50257, 50257, 50257]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[   79,   378, 17463, ..., 50257, 50257, 50257]],\n",
       "\n",
       "       [[  462, 21348,  3450, ..., 50257, 50257, 50257]],\n",
       "\n",
       "       [[   66, 14501, 48241, ..., 50257, 50257, 50257]]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 498M/498M [06:47<00:00, 1.22MB/s] \n",
      "c:\\Users\\badje\\OneDrive\\Bureau\\Cours_M2\\NLP\\projet\\Recipe_generator\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:127: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\badje\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "All model checkpoint layers were used when initializing TFGPT2Model.\n",
      "\n",
      "All the layers of TFGPT2Model were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2Model for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFGPT2Model.from_pretrained('gpt2')\n",
    "config = GPT2Config.from_pretrained('gpt2')\n",
    "config.output_hidden_states = True\n",
    "model.config = config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\badje\\OneDrive\\Bureau\\Cours_M2\\NLP\\projet\\Recipe_generator\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\badje\\OneDrive\\Bureau\\Cours_M2\\NLP\\projet\\Recipe_generator\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\badje\\OneDrive\\Bureau\\Cours_M2\\NLP\\projet\\Recipe_generator\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\badje\\OneDrive\\Bureau\\Cours_M2\\NLP\\projet\\Recipe_generator\\venv\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1476, in train_step\n        data = data_adapter.expand_1d(data)\n\n    AttributeError: module 'keras.engine.data_adapter' has no attribute 'expand_1d'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [58], line 13\u001b[0m\n\u001b[0;32m      6\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[0;32m      7\u001b[0m   loss\u001b[39m=\u001b[39mloss,\n\u001b[0;32m      8\u001b[0m   optimizer\u001b[39m=\u001b[39moptimizer,\n\u001b[0;32m      9\u001b[0m   metrics\u001b[39m=\u001b[39mmetric\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m     14\u001b[0m   X_train,\n\u001b[0;32m     15\u001b[0m   y_train,\n\u001b[0;32m     16\u001b[0m   \u001b[39m# batch_size=batch_size,\u001b[39;49;00m\n\u001b[0;32m     17\u001b[0m   epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[0;32m     18\u001b[0m   validation_data\u001b[39m=\u001b[39;49m(X_test, y_test)\n\u001b[0;32m     19\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\badje\\OneDrive\\Bureau\\Cours_M2\\NLP\\projet\\Recipe_generator\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filekak2hfik.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\badje\\OneDrive\\Bureau\\Cours_M2\\NLP\\projet\\Recipe_generator\\venv\\lib\\site-packages\\transformers\\modeling_tf_utils.py:1476\u001b[0m, in \u001b[0;36mTFPreTrainedModel.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1474\u001b[0m output_to_label \u001b[39m=\u001b[39m {val: key \u001b[39mfor\u001b[39;00m key, val \u001b[39min\u001b[39;00m label_to_output\u001b[39m.\u001b[39mitems()}\n\u001b[0;32m   1475\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_using_dummy_loss:\n\u001b[1;32m-> 1476\u001b[0m     data \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39;49mexpand_1d(data)\n\u001b[0;32m   1477\u001b[0m x, y, sample_weight \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39munpack_x_y_sample_weight(data)\n\u001b[0;32m   1478\u001b[0m \u001b[39m# If the inputs are mutable dictionaries, make a shallow copy of them because we will modify\u001b[39;00m\n\u001b[0;32m   1479\u001b[0m \u001b[39m# them during input/label pre-processing. This avoids surprising the user by wrecking their data.\u001b[39;00m\n\u001b[0;32m   1480\u001b[0m \u001b[39m# In addition, modifying mutable Python inputs makes XLA compilation impossible.\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: in user code:\n\n    File \"c:\\Users\\badje\\OneDrive\\Bureau\\Cours_M2\\NLP\\projet\\Recipe_generator\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\badje\\OneDrive\\Bureau\\Cours_M2\\NLP\\projet\\Recipe_generator\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\badje\\OneDrive\\Bureau\\Cours_M2\\NLP\\projet\\Recipe_generator\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\badje\\OneDrive\\Bureau\\Cours_M2\\NLP\\projet\\Recipe_generator\\venv\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1476, in train_step\n        data = data_adapter.expand_1d(data)\n\n    AttributeError: module 'keras.engine.data_adapter' has no attribute 'expand_1d'\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
    "\n",
    "model.compile(\n",
    "  loss=loss,\n",
    "  optimizer=optimizer,\n",
    "  metrics=metric\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "  X_train,\n",
    "  y_train,\n",
    "  # batch_size=batch_size,\n",
    "  epochs=10,\n",
    "  validation_data=(X_test, y_test)\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "befec533deea68de54ca62dbffdf5cda37e71d4b7ad2a5c99b38a8c68b455b77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
